{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# https://www.nih.gov/news-events/news-releases/nih-clinical-center-provides-one-largest-publicly-available-chest-x-ray-datasets-scientific-community\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms as tf\n",
    "from os import walk\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import image\n",
    "from torchvision import transforms\n",
    "# Set ipython's max row display\n",
    "pd.set_option('display.max_row', 1000)\n",
    "\n",
    "# Set iPython's max column width to 50\n",
    "pd.set_option('display.max_columns', 50)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_df2.csv')\n",
    "test_df = pd.read_csv('test_df2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Finding Label</th>\n",
       "      <th>Image Index</th>\n",
       "      <th>h</th>\n",
       "      <th>w</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28192</th>\n",
       "      <td>1</td>\n",
       "      <td>00008788_000.png</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19891</th>\n",
       "      <td>5</td>\n",
       "      <td>00006273_001.png</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64862</th>\n",
       "      <td>1</td>\n",
       "      <td>00020170_004.png</td>\n",
       "      <td>2544.0</td>\n",
       "      <td>3056.0</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48542</th>\n",
       "      <td>13</td>\n",
       "      <td>00014971_006.png</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85752</th>\n",
       "      <td>5</td>\n",
       "      <td>00030047_000.png</td>\n",
       "      <td>3056.0</td>\n",
       "      <td>2544.0</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51076</th>\n",
       "      <td>1</td>\n",
       "      <td>00015806_006.png</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79146</th>\n",
       "      <td>1</td>\n",
       "      <td>00026521_000.png</td>\n",
       "      <td>3056.0</td>\n",
       "      <td>2544.0</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70437</th>\n",
       "      <td>8</td>\n",
       "      <td>00022156_003.png</td>\n",
       "      <td>2544.0</td>\n",
       "      <td>3056.0</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43103</th>\n",
       "      <td>8</td>\n",
       "      <td>00013287_000.png</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22652</th>\n",
       "      <td>6</td>\n",
       "      <td>00007065_002.png</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Finding Label       Image Index       h       w      x      y\n",
       "28192              1  00008788_000.png  2048.0  2500.0  0.168  0.168\n",
       "19891              5  00006273_001.png  2048.0  2500.0  0.171  0.171\n",
       "64862              1  00020170_004.png  2544.0  3056.0  0.139  0.139\n",
       "48542             13  00014971_006.png  2048.0  2500.0  0.168  0.168\n",
       "85752              5  00030047_000.png  3056.0  2544.0  0.139  0.139\n",
       "51076              1  00015806_006.png  2048.0  2500.0  0.168  0.168\n",
       "79146              1  00026521_000.png  3056.0  2544.0  0.139  0.139\n",
       "70437              8  00022156_003.png  2544.0  3056.0  0.139  0.139\n",
       "43103              8  00013287_000.png  2048.0  2500.0  0.168  0.168\n",
       "22652              6  00007065_002.png  2048.0  2500.0  0.168  0.168"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     50500\n",
       "4      8758\n",
       "8      8280\n",
       "5      5361\n",
       "6      2429\n",
       "3      2198\n",
       "12     2056\n",
       "0      1515\n",
       "9      1241\n",
       "13     1122\n",
       "7       969\n",
       "11      902\n",
       "10      868\n",
       "14      235\n",
       "2        90\n",
       "Name: Finding Label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Finding Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_df['Image Index'] == '00030181_001.png').value_counts()\n",
    "# 00028247_001.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "my_path = \"../Datasets/Lungs_Dataset/Xray\" if platform.system() == 'Windows' else \"datasets/data/images\"\n",
    "filename_list = []\n",
    "for root, dirs, files in os.walk(my_path, topdown=True):\n",
    "    for name in files:\n",
    "        filename_list.append(name)\n",
    "#         with Image.open(os.path.join(\"datasets/data/images\", name)) as f:\n",
    "#             print(len(f.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     82995\n",
       "False     3529\n",
       "Name: Image Index, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Image Index'].isin(filename_list).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['Image Index'].isin(filename_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    82995\n",
       "Name: Image Index, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Image Index'].isin(filename_list).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    82995\n",
       "Name: Image Index, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Image Index'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[test_df['Image Index'].isin(filename_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Finding Label</th>\n",
       "      <th>Image Index</th>\n",
       "      <th>h</th>\n",
       "      <th>w</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14810</th>\n",
       "      <td>5</td>\n",
       "      <td>00017606_010.png</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7132</th>\n",
       "      <td>8</td>\n",
       "      <td>00010936_012.png</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6155</th>\n",
       "      <td>1</td>\n",
       "      <td>00009892_031.png</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15990</th>\n",
       "      <td>13</td>\n",
       "      <td>00018867_015.png</td>\n",
       "      <td>2544.0</td>\n",
       "      <td>3056.0</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15408</th>\n",
       "      <td>1</td>\n",
       "      <td>00018253_030.png</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18370</th>\n",
       "      <td>13</td>\n",
       "      <td>00021420_015.png</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>1</td>\n",
       "      <td>00006271_007.png</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>1</td>\n",
       "      <td>00004342_031.png</td>\n",
       "      <td>2368.0</td>\n",
       "      <td>3040.0</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>6</td>\n",
       "      <td>00000643_008.png</td>\n",
       "      <td>2991.0</td>\n",
       "      <td>2766.0</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>4</td>\n",
       "      <td>00002316_005.png</td>\n",
       "      <td>2657.0</td>\n",
       "      <td>2918.0</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Finding Label       Image Index       h       w      x      y\n",
       "14810              5  00017606_010.png  2048.0  2500.0  0.168  0.168\n",
       "7132               8  00010936_012.png  2048.0  2500.0  0.168  0.168\n",
       "6155               1  00009892_031.png  2500.0  2048.0  0.168  0.168\n",
       "15990             13  00018867_015.png  2544.0  3056.0  0.139  0.139\n",
       "15408              1  00018253_030.png  2048.0  2500.0  0.168  0.168\n",
       "18370             13  00021420_015.png  2048.0  2500.0  0.168  0.168\n",
       "3791               1  00006271_007.png  2048.0  2500.0  0.171  0.171\n",
       "2564               1  00004342_031.png  2368.0  3040.0  0.139  0.139\n",
       "616                6  00000643_008.png  2991.0  2766.0  0.143  0.143\n",
       "1618               4  00002316_005.png  2657.0  2918.0  0.143  0.143"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RescaleImage(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "            \n",
    "        The samples coming into this class will have its images reduced assuming\n",
    "        the input is a h, w, c numpy array\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        h, w = image.size\n",
    "\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = image.resize((new_h, new_w))\n",
    "\n",
    "        return {'image': img, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        image = np.array(image)\n",
    "        if len(image.shape) > 2:\n",
    "            image = image[:,:,0]\n",
    "\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        return {'image': torch.FloatTensor(image).unsqueeze(0),\n",
    "#         return {'image': torch.from_numpy(image),                \n",
    "                'label': torch.from_numpy(np.array(label))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  print([Image.open('../Datasets/Lungs_Dataset/Xray/'+train_df['Image Index'][each_import]).size for each_import in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note this will return an Image object, of h and w, and its corresponding label\n",
    "class CovidLungsDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, dataframe, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.dataframe['Image Index'][idx])\n",
    "        my_image = Image.open(img_name)        \n",
    "        if len(my_image.size) > 2:\n",
    "            assert len(my_image.size) > 2\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        label = row['Finding Label']\n",
    "        sample = {'image': my_image, 'label': label}\n",
    "        sample.to(device)\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_train_set = CovidLungsDataset(train_df, my_path, transform=transforms.Compose([\n",
    "        RescaleImage(200),\n",
    "        ToTensor()\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Size([1, 200, 200]), tensor(11))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''The original data coming out of the Dataset is a dictionary, \n",
    "the image is an Image object with the corresponding label.\n",
    "The size of all of these images are 1024 by 1024.\n",
    "The RescaleImage will convert the Image object to an Image object with 200x200 in size, \n",
    "leaving the label alone.\n",
    "The ToTensor will convert the Image object with 200x200 to tensors of 1x200x200'''\n",
    "from random import randint\n",
    "a_sample = my_train_set.__getitem__(randint(0,256))\n",
    "my_image = a_sample['image']\n",
    "my_label = a_sample['label']\n",
    "#imshow will work if it's h,w,c or h,w\n",
    "#torch is c,h,w\n",
    "#line below can be used if you don't use ToTensor\n",
    "# plt.imshow(my_image)\n",
    "type(my_image), my_image.shape, my_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(my_image.squeeze(0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "batch_loader_params = {\n",
    "    \"batch_size\": 5,\n",
    "    \"shuffle\": True,\n",
    "    \"num_workers\": 0 if platform.system() == 'Windows' else 2\n",
    "}\n",
    "dataloader = DataLoader(my_train_set, **batch_loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter(dataloader).next()\n",
    "# for i, each in enumerate(dataloader):\n",
    "#     print(each['image'].shape, each['label'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_samples = iter(dataloader)\n",
    "# samples = batch_samples.next()\n",
    "# datset_batch = torchvision.utils.make_grid(samples['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,10))\n",
    "# for index, each in enumerate(datset_batch):\n",
    "#     plt.imshow(each.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_size(input_size: int, kernel_size: int, stride: int = 1, padding: int = 0):\n",
    "    # https://cs231n.github.io/convolutional-networks/\n",
    "    spatial_size = (input_size - kernel_size + 2 * padding)/stride + 1\n",
    "    assert spatial_size % 1 == 0\n",
    "    assert spatial_size > 0\n",
    "    return int(spatial_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "print(spatial_size(200, 51))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "print(spatial_size(75, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(spatial_size(13, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 200, kernel_size=(51, 51), stride=(1, 1))\n",
      "  (conv2): Conv2d(200, 75, kernel_size=(50, 50), stride=(1, 1))\n",
      "  (conv3): Conv2d(75, 13, kernel_size=(8, 8), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=117, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=15, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 200, 51, 1)\n",
    "        self.conv2 = nn.Conv2d(200, 75, 50, 1)        \n",
    "        self.conv3 = nn.Conv2d(75, 13, 8, 1)  \n",
    "        self.fc1 = nn.Linear(3*3*13, 32)\n",
    "        self.fc2 = nn.Linear(32, 15)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x)) # torch.Size([5, 1, 200, 200]) ==> torch.Size([5, 200, 150, 150])\n",
    "        x = F.max_pool2d(x, 2, 2) # torch.Size([5, 200, 150, 150]) ==> torch.Size([5, 200, 75, 75])\n",
    "        x = F.relu(self.conv2(x)) # torch.Size([5, 200, 75, 75]) ==> torch.Size([5, 75, 26, 26])\n",
    "        x = F.max_pool2d(x, 2, 2) # torch.Size([5, 75, 26, 26]) ==> torch.Size([5, 75, 13, 13])\n",
    "        x = F.relu(self.conv3(x)) # torch.Size([5, 75, 13, 13]) ==> torch.Size([5, 13, 6, 6])\n",
    "        x = F.max_pool2d(x, 2, 2) # torch.Size([5, 13, 6, 6]) ==> torch.Size([5, 13, 3, 3])\n",
    "        x = x.view(-1, 3*3*13)  # torch.Size([5, 13, 3, 3]) ==> torch.Size([5*32, 3*3*13])\n",
    "        x = F.relu(self.fc1(x))   # torch.Size([5*32, 3*3*13]) ==> torch.Size([5, 32])\n",
    "        x = self.fc2(x)           # torch.Size([5, 32]) ==> torch.Size([5, 15])\n",
    "        # # There's no activation at the final layer because of the criterion of CEL\n",
    "#         return x\n",
    "        return torch.log_softmax(x, dim=-1)\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net.to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.NLLLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 4.06250\n",
      "[1,     2] loss: 4470536.56250\n",
      "[1,     3] loss: 5154667.75000\n",
      "[1,     4] loss: 5197298.67578\n",
      "[1,     5] loss: 5197300.80633\n",
      "[1,     6] loss: 5470878.18133\n",
      "[1,     7] loss: 5470947.38091\n",
      "[1,     8] loss: 5621659.80278\n",
      "[1,     9] loss: 5621662.39446\n",
      "[1,    10] loss: 5621665.01035\n",
      "[1,    11] loss: 5621667.57748\n",
      "[1,    12] loss: 5621670.08818\n",
      "[1,    13] loss: 5621672.61248\n",
      "[1,    14] loss: 5621675.11744\n",
      "[1,    15] loss: 5621677.58928\n",
      "[1,    16] loss: 5621680.10285\n",
      "[1,    17] loss: 5621682.60778\n",
      "[1,    18] loss: 5621684.99020\n",
      "[1,    19] loss: 5621687.33970\n",
      "[1,    20] loss: 5621689.68018\n",
      "[1,    21] loss: 5621692.07051\n",
      "[1,    22] loss: 5621694.49949\n",
      "[1,    23] loss: 5621696.90794\n",
      "[1,    24] loss: 5621699.05175\n",
      "[1,    25] loss: 5621701.30669\n",
      "[1,    26] loss: 5621703.66442\n",
      "[1,    27] loss: 5621706.02275\n",
      "[1,    28] loss: 5621708.15130\n",
      "[1,    29] loss: 5621710.34438\n",
      "[1,    30] loss: 5621712.87823\n",
      "[1,    31] loss: 5621714.91864\n",
      "[1,    32] loss: 5621717.36402\n",
      "[1,    33] loss: 5621719.42765\n",
      "[1,    34] loss: 5621721.53758\n",
      "[1,    35] loss: 5621723.41959\n",
      "[1,    36] loss: 5621725.12644\n",
      "[1,    37] loss: 5621726.60079\n",
      "[1,    38] loss: 5621728.02635\n",
      "[1,    39] loss: 5621729.80222\n",
      "[1,    40] loss: 5621731.75747\n",
      "[1,    41] loss: 5621733.69624\n",
      "[1,    42] loss: 5621735.14435\n",
      "[1,    43] loss: 5621737.17648\n",
      "[1,    44] loss: 5621738.64348\n",
      "[1,    45] loss: 5621740.22886\n",
      "[1,    46] loss: 5621742.03066\n",
      "[1,    47] loss: 5621743.86135\n",
      "[1,    48] loss: 5621745.38765\n",
      "[1,    49] loss: 5621747.32943\n",
      "[1,    50] loss: 5621749.04075\n",
      "[1,    51] loss: 5621750.47059\n",
      "[1,    52] loss: 5621752.25009\n",
      "[1,    53] loss: 5621754.26790\n",
      "[1,    54] loss: 5621755.39194\n",
      "[1,    55] loss: 5621757.36606\n",
      "[1,    56] loss: 5621758.08616\n",
      "[1,    57] loss: 5621759.09888\n",
      "[1,    58] loss: 5621760.43012\n",
      "[1,    59] loss: 5621762.09946\n",
      "[1,    60] loss: 5621763.62502\n",
      "[1,    61] loss: 5621764.22496\n",
      "[1,    62] loss: 5621765.32415\n",
      "[1,    63] loss: 5621767.81900\n",
      "[1,    64] loss: 5621769.25700\n",
      "[1,    65] loss: 5621771.15510\n",
      "[1,    66] loss: 5621772.83711\n",
      "[1,    67] loss: 5621774.28284\n",
      "[1,    68] loss: 5621775.56070\n",
      "[1,    69] loss: 5621776.71193\n",
      "[1,    70] loss: 5621777.59449\n",
      "[1,    71] loss: 5621778.60336\n",
      "[1,    72] loss: 5621779.96173\n",
      "[1,    73] loss: 5621782.15649\n",
      "[1,    74] loss: 5621783.08756\n",
      "[1,    75] loss: 5621784.93235\n",
      "[1,    76] loss: 5621786.28063\n",
      "[1,    77] loss: 5621787.93824\n",
      "[1,    78] loss: 5621788.77535\n",
      "[1,    79] loss: 5621789.18105\n",
      "[1,    80] loss: 5621790.84172\n",
      "[1,    81] loss: 5621792.23504\n",
      "[1,    82] loss: 5621795.28725\n",
      "[1,    83] loss: 5621796.52720\n",
      "[1,    84] loss: 5621798.84407\n",
      "[1,    85] loss: 5621801.39800\n",
      "[1,    86] loss: 5621803.77748\n",
      "[1,    87] loss: 5621805.44401\n",
      "[1,    88] loss: 5621807.59441\n",
      "[1,    89] loss: 5621808.42161\n",
      "[1,    90] loss: 5621810.62180\n",
      "[1,    91] loss: 5621812.60456\n",
      "[1,    92] loss: 5621815.59289\n",
      "[1,    93] loss: 5621817.78894\n",
      "[1,    94] loss: 5621820.75498\n",
      "[1,    95] loss: 5621822.60652\n",
      "[1,    96] loss: 5621823.97615\n",
      "[1,    97] loss: 5621826.20494\n",
      "[1,    98] loss: 5621828.29412\n",
      "[1,    99] loss: 5621828.84002\n",
      "[1,   100] loss: 5621829.39640\n",
      "[1,   101] loss: 5621830.36276\n",
      "[1,   102] loss: 5621832.03510\n",
      "[1,   103] loss: 5621834.68365\n",
      "[1,   104] loss: 5621836.22689\n",
      "[1,   105] loss: 5621838.12989\n",
      "[1,   106] loss: 5621840.41169\n",
      "[1,   107] loss: 5621841.80079\n",
      "[1,   108] loss: 5621844.57634\n",
      "[1,   109] loss: 5621846.76298\n",
      "[1,   110] loss: 5621848.81086\n",
      "[1,   111] loss: 5621849.85367\n",
      "[1,   112] loss: 5621851.14157\n",
      "[1,   113] loss: 5621852.48477\n",
      "[1,   114] loss: 5621854.00790\n",
      "[1,   115] loss: 5621855.62786\n",
      "[1,   116] loss: 5621856.95103\n",
      "[1,   117] loss: 5621858.35035\n",
      "[1,   118] loss: 5621860.94609\n",
      "[1,   119] loss: 5621863.07728\n",
      "[1,   120] loss: 5621865.44572\n",
      "[1,   121] loss: 5621866.97876\n",
      "[1,   122] loss: 5621870.19602\n",
      "[1,   123] loss: 5621870.84998\n",
      "[1,   124] loss: 5621873.24966\n",
      "[1,   125] loss: 5621874.53511\n",
      "[1,   126] loss: 5621875.52854\n",
      "[1,   127] loss: 5621878.53482\n",
      "[1,   128] loss: 5621880.27856\n",
      "[1,   129] loss: 5621881.95556\n",
      "[1,   130] loss: 5621884.11424\n",
      "[1,   131] loss: 5621885.52757\n",
      "[1,   132] loss: 5621887.76749\n",
      "[1,   133] loss: 5621889.82899\n",
      "[1,   134] loss: 5621891.85807\n",
      "[1,   135] loss: 5621892.53636\n",
      "[1,   136] loss: 5621894.07244\n",
      "[1,   137] loss: 5621895.07232\n",
      "[1,   138] loss: 5621896.53225\n",
      "[1,   139] loss: 5621898.85985\n",
      "[1,   140] loss: 5621900.54311\n",
      "[1,   141] loss: 5621902.45770\n",
      "[1,   142] loss: 5621903.10950\n",
      "[1,   143] loss: 5621905.52400\n",
      "[1,   144] loss: 5621906.83618\n",
      "[1,   145] loss: 5621908.58145\n",
      "[1,   146] loss: 5621909.91579\n",
      "[1,   147] loss: 5621911.58886\n",
      "[1,   148] loss: 5621913.47402\n",
      "[1,   149] loss: 5621914.89462\n",
      "[1,   150] loss: 5621918.16669\n",
      "[1,   151] loss: 5621919.93817\n",
      "[1,   152] loss: 5621920.54768\n",
      "[1,   153] loss: 5621922.65248\n",
      "[1,   154] loss: 5621924.49785\n",
      "[1,   155] loss: 5621925.43335\n",
      "[1,   156] loss: 5621927.04598\n",
      "[1,   157] loss: 5621928.37421\n",
      "[1,   158] loss: 5621929.47184\n",
      "[1,   159] loss: 5621930.05163\n",
      "[1,   160] loss: 5621931.54049\n",
      "[1,   161] loss: 5621932.86434\n",
      "[1,   162] loss: 5621934.18733\n",
      "[1,   163] loss: 5621935.43077\n",
      "[1,   164] loss: 5621935.96305\n",
      "[1,   165] loss: 5621938.41044\n",
      "[1,   166] loss: 5621941.28776\n",
      "[1,   167] loss: 5621942.81990\n",
      "[1,   168] loss: 5621944.20909\n",
      "[1,   169] loss: 5621945.60830\n",
      "[1,   170] loss: 5621946.10453\n",
      "[1,   171] loss: 5621947.84163\n",
      "[1,   172] loss: 5621949.70281\n",
      "[1,   173] loss: 5621950.64733\n",
      "[1,   174] loss: 5621952.35918\n",
      "[1,   175] loss: 5621955.44757\n",
      "[1,   176] loss: 5621957.19721\n",
      "[1,   177] loss: 5621959.27702\n",
      "[1,   178] loss: 5621960.77831\n",
      "[1,   179] loss: 5621961.72459\n",
      "[1,   180] loss: 5621964.42790\n",
      "[1,   181] loss: 5621966.03482\n",
      "[1,   182] loss: 5621966.94969\n",
      "[1,   183] loss: 5621968.00342\n",
      "[1,   184] loss: 5621969.64699\n",
      "[1,   185] loss: 5621971.73120\n",
      "[1,   186] loss: 5621973.33144\n",
      "[1,   187] loss: 5621974.57023\n",
      "[1,   188] loss: 5621976.56498\n",
      "[1,   189] loss: 5621977.85877\n",
      "[1,   190] loss: 5621978.38772\n",
      "[1,   191] loss: 5621980.04085\n",
      "[1,   192] loss: 5621981.31344\n",
      "[1,   193] loss: 5621983.28433\n",
      "[1,   194] loss: 5621984.52901\n",
      "[1,   195] loss: 5621985.75662\n",
      "[1,   196] loss: 5621986.28141\n",
      "[1,   197] loss: 5621987.49833\n",
      "[1,   198] loss: 5621988.37621\n",
      "[1,   199] loss: 5621990.72653\n",
      "[1,   200] loss: 5621992.30966\n",
      "[1,   201] loss: 5621994.66867\n",
      "[1,   202] loss: 5621996.99390\n",
      "[1,   203] loss: 5621998.61342\n",
      "[1,   204] loss: 5621999.63034\n",
      "[1,   205] loss: 5622001.53755\n",
      "[1,   206] loss: 5622002.89738\n",
      "[1,   207] loss: 5622004.11275\n",
      "[1,   208] loss: 5622006.02920\n",
      "[1,   209] loss: 5622007.24271\n",
      "[1,   210] loss: 5622008.88179\n",
      "[1,   211] loss: 5622010.75126\n",
      "[1,   212] loss: 5622012.90345\n",
      "[1,   213] loss: 5622014.16585\n",
      "[1,   214] loss: 5622016.48920\n",
      "[1,   215] loss: 5622018.55050\n",
      "[1,   216] loss: 5622020.34635\n",
      "[1,   217] loss: 5622021.48328\n",
      "[1,   218] loss: 5622022.64288\n",
      "[1,   219] loss: 5622024.34913\n",
      "[1,   220] loss: 5622024.88746\n",
      "[1,   221] loss: 5622026.24006\n",
      "[1,   222] loss: 5622028.27240\n",
      "[1,   223] loss: 5622028.80110\n",
      "[1,   224] loss: 5622029.32413\n",
      "[1,   225] loss: 5622029.83794\n",
      "[1,   226] loss: 5622031.06571\n",
      "[1,   227] loss: 5622032.60983\n",
      "[1,   228] loss: 5622035.25034\n",
      "[1,   229] loss: 5622036.91554\n",
      "[1,   230] loss: 5622037.99262\n",
      "[1,   231] loss: 5622040.56666\n",
      "[1,   232] loss: 5622041.03306\n",
      "[1,   233] loss: 5622043.76423\n",
      "[1,   234] loss: 5622044.65664\n",
      "[1,   235] loss: 5622045.45885\n",
      "[1,   236] loss: 5622047.07925\n",
      "[1,   237] loss: 5622047.96755\n",
      "[1,   238] loss: 5622049.53555\n",
      "[1,   239] loss: 5622050.41930\n",
      "[1,   240] loss: 5622053.96931\n",
      "[1,   241] loss: 5622055.88247\n",
      "[1,   242] loss: 5622057.64021\n",
      "[1,   243] loss: 5622059.57622\n",
      "[1,   244] loss: 5622061.43039\n",
      "[1,   245] loss: 5622063.12919\n",
      "[1,   246] loss: 5622065.91226\n",
      "[1,   247] loss: 5622067.27074\n",
      "[1,   248] loss: 5622068.56647\n",
      "[1,   249] loss: 5622069.76878\n",
      "[1,   250] loss: 5622071.74012\n",
      "[1,   251] loss: 5622074.06256\n",
      "[1,   252] loss: 5622075.51759\n",
      "[1,   253] loss: 5622076.39684\n",
      "[1,   254] loss: 5622077.30134\n",
      "[1,   255] loss: 5622079.20578\n",
      "[1,   256] loss: 5622080.23228\n",
      "[1,   257] loss: 5622082.28040\n",
      "[1,   258] loss: 5622084.67734\n",
      "[1,   259] loss: 5622086.04249\n",
      "[1,   260] loss: 5622088.88982\n",
      "[1,   261] loss: 5622090.46562\n",
      "[1,   262] loss: 5622091.59421\n",
      "[1,   263] loss: 5622093.15869\n",
      "[1,   264] loss: 5622094.07751\n",
      "[1,   265] loss: 5622095.32315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   266] loss: 5622097.21058\n",
      "[1,   267] loss: 5622099.32780\n",
      "[1,   268] loss: 5622100.91128\n",
      "[1,   269] loss: 5622102.60901\n",
      "[1,   270] loss: 5622104.37409\n",
      "[1,   271] loss: 5622106.09053\n",
      "[1,   272] loss: 5622108.62552\n",
      "[1,   273] loss: 5622109.22879\n",
      "[1,   274] loss: 5622111.21660\n",
      "[1,   275] loss: 5622113.20691\n",
      "[1,   276] loss: 5622113.81174\n",
      "[1,   277] loss: 5622115.08026\n",
      "[1,   278] loss: 5622116.76002\n",
      "[1,   279] loss: 5622117.90542\n",
      "[1,   280] loss: 5622118.82009\n",
      "[1,   281] loss: 5622120.35297\n",
      "[1,   282] loss: 5622121.59039\n",
      "[1,   283] loss: 5622123.40580\n",
      "[1,   284] loss: 5622125.88912\n",
      "[1,   285] loss: 5622126.44443\n",
      "[1,   286] loss: 5622127.33756\n",
      "[1,   287] loss: 5622128.75253\n",
      "[1,   288] loss: 5622131.22701\n",
      "[1,   289] loss: 5622132.95340\n",
      "[1,   290] loss: 5622134.18624\n",
      "[1,   291] loss: 5622135.05531\n",
      "[1,   292] loss: 5622137.36475\n",
      "[1,   293] loss: 5622138.22543\n",
      "[1,   294] loss: 5622139.09918\n",
      "[1,   295] loss: 5622141.78978\n",
      "[1,   296] loss: 5622143.02544\n",
      "[1,   297] loss: 5622146.47027\n",
      "[1,   298] loss: 5622147.34049\n",
      "[1,   299] loss: 5622147.82585\n",
      "[1,   300] loss: 5622149.48704\n",
      "[1,   301] loss: 5622151.89927\n",
      "[1,   302] loss: 5622153.63598\n",
      "[1,   303] loss: 5622155.36486\n",
      "[1,   304] loss: 5622156.70555\n",
      "[1,   305] loss: 5622159.30464\n",
      "[1,   306] loss: 5622160.58659\n",
      "[1,   307] loss: 5622161.46815\n",
      "[1,   308] loss: 5622163.35874\n",
      "[1,   309] loss: 5622164.24378\n",
      "[1,   310] loss: 5622166.40988\n",
      "[1,   311] loss: 5622168.25642\n",
      "[1,   312] loss: 5622169.37835\n",
      "[1,   313] loss: 5622171.09493\n",
      "[1,   314] loss: 5622172.73745\n",
      "[1,   315] loss: 5622173.72949\n",
      "[1,   316] loss: 5622176.74597\n",
      "[1,   317] loss: 5622178.04803\n",
      "[1,   318] loss: 5622180.89376\n",
      "[1,   319] loss: 5622183.60261\n",
      "[1,   320] loss: 5622184.51364\n",
      "[1,   321] loss: 5622185.81415\n",
      "[1,   322] loss: 5622187.49429\n",
      "[1,   323] loss: 5622189.91801\n",
      "[1,   324] loss: 5622190.82888\n",
      "[1,   325] loss: 5622193.16117\n",
      "[1,   326] loss: 5622195.32236\n",
      "[1,   327] loss: 5622196.70005\n",
      "[1,   328] loss: 5622198.35194\n",
      "[1,   329] loss: 5622199.71838\n",
      "[1,   330] loss: 5622202.39753\n",
      "[1,   331] loss: 5622203.68022\n",
      "[1,   332] loss: 5622204.63443\n",
      "[1,   333] loss: 5622206.00464\n",
      "[1,   334] loss: 5622207.26146\n",
      "[1,   335] loss: 5622209.25369\n",
      "[1,   336] loss: 5622210.55045\n",
      "[1,   337] loss: 5622211.90542\n",
      "[1,   338] loss: 5622213.19562\n",
      "[1,   339] loss: 5622214.84985\n",
      "[1,   340] loss: 5622216.18715\n",
      "[1,   341] loss: 5622218.17495\n",
      "[1,   342] loss: 5622220.04195\n",
      "[1,   343] loss: 5622221.68520\n",
      "[1,   344] loss: 5622222.61076\n",
      "[1,   345] loss: 5622223.53199\n",
      "[1,   346] loss: 5622224.86402\n",
      "[1,   347] loss: 5622226.80881\n",
      "[1,   348] loss: 5622229.05406\n",
      "[1,   349] loss: 5622231.36926\n",
      "[1,   350] loss: 5622232.65108\n",
      "[1,   351] loss: 5622234.29671\n",
      "[1,   352] loss: 5622237.20241\n",
      "[1,   353] loss: 5622238.14315\n",
      "[1,   354] loss: 5622239.79721\n",
      "[1,   355] loss: 5622241.14127\n",
      "[1,   356] loss: 5622242.10955\n",
      "[1,   357] loss: 5622243.45357\n",
      "[1,   358] loss: 5622245.31438\n",
      "[1,   359] loss: 5622247.94715\n",
      "[1,   360] loss: 5622249.15327\n",
      "[1,   361] loss: 5622249.72109\n",
      "[1,   362] loss: 5622250.62157\n",
      "[1,   363] loss: 5622252.36046\n",
      "[1,   364] loss: 5622254.42885\n",
      "[1,   365] loss: 5622254.97641\n",
      "[1,   366] loss: 5622256.17105\n",
      "[1,   367] loss: 5622257.05348\n",
      "[1,   368] loss: 5622257.92943\n",
      "[1,   369] loss: 5622260.15096\n",
      "[1,   370] loss: 5622261.49351\n",
      "[1,   371] loss: 5622263.30254\n",
      "[1,   372] loss: 5622264.92975\n",
      "[1,   373] loss: 5622267.39254\n",
      "[1,   374] loss: 5622269.60916\n",
      "[1,   375] loss: 5622271.91934\n",
      "[1,   376] loss: 5622274.14651\n",
      "[1,   377] loss: 5622276.87299\n",
      "[1,   378] loss: 5622278.55311\n",
      "[1,   379] loss: 5622279.81751\n",
      "[1,   380] loss: 5622280.34607\n",
      "[1,   381] loss: 5622282.51813\n",
      "[1,   382] loss: 5622283.44743\n",
      "[1,   383] loss: 5622283.99216\n",
      "[1,   384] loss: 5622286.06170\n",
      "[1,   385] loss: 5622287.63007\n",
      "[1,   386] loss: 5622288.17700\n",
      "[1,   387] loss: 5622289.85363\n",
      "[1,   388] loss: 5622292.60036\n",
      "[1,   389] loss: 5622294.72676\n",
      "[1,   390] loss: 5622296.37759\n",
      "[1,   391] loss: 5622297.72275\n",
      "[1,   392] loss: 5622298.27274\n",
      "[1,   393] loss: 5622299.91002\n",
      "[1,   394] loss: 5622302.02605\n",
      "[1,   395] loss: 5622303.86518\n",
      "[1,   396] loss: 5622306.00889\n",
      "[1,   397] loss: 5622307.32059\n",
      "[1,   398] loss: 5622308.25482\n",
      "[1,   399] loss: 5622309.18814\n",
      "[1,   400] loss: 5622311.25544\n",
      "[1,   401] loss: 5622312.11149\n",
      "[1,   402] loss: 5622313.82093\n",
      "[1,   403] loss: 5622315.05507\n",
      "[1,   404] loss: 5622317.20289\n",
      "[1,   405] loss: 5622318.77043\n",
      "[1,   406] loss: 5622321.79616\n",
      "[1,   407] loss: 5622323.47099\n",
      "[1,   408] loss: 5622324.78352\n",
      "[1,   409] loss: 5622325.30766\n",
      "[1,   410] loss: 5622327.50306\n",
      "[1,   411] loss: 5622329.93116\n",
      "[1,   412] loss: 5622332.17324\n",
      "[1,   413] loss: 5622333.45083\n",
      "[1,   414] loss: 5622335.32175\n",
      "[1,   415] loss: 5622336.26419\n",
      "[1,   416] loss: 5622338.57618\n",
      "[1,   417] loss: 5622340.17478\n",
      "[1,   418] loss: 5622341.91333\n",
      "[1,   419] loss: 5622343.72954\n",
      "[1,   420] loss: 5622345.65306\n",
      "[1,   421] loss: 5622346.21714\n",
      "[1,   422] loss: 5622347.45999\n",
      "[1,   423] loss: 5622350.32683\n",
      "[1,   424] loss: 5622351.63678\n",
      "[1,   425] loss: 5622353.13803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/senhmo/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/senhmo/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/senhmo/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/senhmo/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/senhmo/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/senhmo/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/senhmo/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/senhmo/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-7b957ff0b981>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#         print(outputs.shape, data['label'].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "#         inputs, labels = data['image'], data['label']\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(data['image'])\n",
    "#         print(outputs.shape, data['label'].shape)\n",
    "        loss = criterion(outputs, data['label'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        print('[%d, %5d] loss: %.5f' %\n",
    "              (epoch + 1, i + 1, running_loss / (epoch*i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
