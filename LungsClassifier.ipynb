{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cpu\n"
    }
   ],
   "source": [
    "# https://www.nih.gov/news-events/news-releases/nih-clinical-center-provides-one-largest-publicly-available-chest-x-ray-datasets-scientific-community\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms as tf\n",
    "from os import walk\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import image\n",
    "from torchvision import transforms\n",
    "# Set ipython's max row display\n",
    "pd.set_option('display.max_row', 1000)\n",
    "\n",
    "# Set iPython's max column width to 50\n",
    "pd.set_option('display.max_columns', 50)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_df2.csv')\n",
    "test_df = pd.read_csv('test_df2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       Finding Label       Image Index       h       w         x         y\n12962              1  00004048_009.png  2751.0  2790.0  0.143000  0.143000\n61366              8  00019049_004.png  2991.0  2992.0  0.143000  0.143000\n61806              8  00019176_105.png  2544.0  3056.0  0.139000  0.139000\n62788              1  00019522_010.png  2544.0  3056.0  0.139000  0.139000\n83770              8  00028715_003.png  2021.0  2021.0  0.194311  0.194311\n69366              1  00021750_017.png  2991.0  2794.0  0.143000  0.143000\n32902              1  00010350_033.png  2048.0  2500.0  0.168000  0.168000\n10847              8  00003426_023.png  2048.0  2500.0  0.168000  0.168000\n2910              11  00000981_000.png  2991.0  2992.0  0.143000  0.143000\n26987              8  00008395_004.png  2048.0  2500.0  0.168000  0.168000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Finding Label</th>\n      <th>Image Index</th>\n      <th>h</th>\n      <th>w</th>\n      <th>x</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>12962</td>\n      <td>1</td>\n      <td>00004048_009.png</td>\n      <td>2751.0</td>\n      <td>2790.0</td>\n      <td>0.143000</td>\n      <td>0.143000</td>\n    </tr>\n    <tr>\n      <td>61366</td>\n      <td>8</td>\n      <td>00019049_004.png</td>\n      <td>2991.0</td>\n      <td>2992.0</td>\n      <td>0.143000</td>\n      <td>0.143000</td>\n    </tr>\n    <tr>\n      <td>61806</td>\n      <td>8</td>\n      <td>00019176_105.png</td>\n      <td>2544.0</td>\n      <td>3056.0</td>\n      <td>0.139000</td>\n      <td>0.139000</td>\n    </tr>\n    <tr>\n      <td>62788</td>\n      <td>1</td>\n      <td>00019522_010.png</td>\n      <td>2544.0</td>\n      <td>3056.0</td>\n      <td>0.139000</td>\n      <td>0.139000</td>\n    </tr>\n    <tr>\n      <td>83770</td>\n      <td>8</td>\n      <td>00028715_003.png</td>\n      <td>2021.0</td>\n      <td>2021.0</td>\n      <td>0.194311</td>\n      <td>0.194311</td>\n    </tr>\n    <tr>\n      <td>69366</td>\n      <td>1</td>\n      <td>00021750_017.png</td>\n      <td>2991.0</td>\n      <td>2794.0</td>\n      <td>0.143000</td>\n      <td>0.143000</td>\n    </tr>\n    <tr>\n      <td>32902</td>\n      <td>1</td>\n      <td>00010350_033.png</td>\n      <td>2048.0</td>\n      <td>2500.0</td>\n      <td>0.168000</td>\n      <td>0.168000</td>\n    </tr>\n    <tr>\n      <td>10847</td>\n      <td>8</td>\n      <td>00003426_023.png</td>\n      <td>2048.0</td>\n      <td>2500.0</td>\n      <td>0.168000</td>\n      <td>0.168000</td>\n    </tr>\n    <tr>\n      <td>2910</td>\n      <td>11</td>\n      <td>00000981_000.png</td>\n      <td>2991.0</td>\n      <td>2992.0</td>\n      <td>0.143000</td>\n      <td>0.143000</td>\n    </tr>\n    <tr>\n      <td>26987</td>\n      <td>8</td>\n      <td>00008395_004.png</td>\n      <td>2048.0</td>\n      <td>2500.0</td>\n      <td>0.168000</td>\n      <td>0.168000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1     50500\n4      8758\n8      8280\n5      5361\n6      2429\n3      2198\n12     2056\n0      1515\n9      1241\n13     1122\n7       969\n11      902\n10      868\n14      235\n2        90\nName: Finding Label, dtype: int64"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "train_df['Finding Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_df['Image Index'] == '00030181_001.png').value_counts()\n",
    "# 00028247_001.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "my_path = \"../Datasets/Lungs_Dataset/Xray\" if platform.system() == 'Windows' else \"datasets/data/images\"\n",
    "filename_list = []\n",
    "for root, dirs, files in os.walk(my_path, topdown=True):\n",
    "    for name in files:\n",
    "        filename_list.append(name)\n",
    "#         with Image.open(os.path.join(\"datasets/data/images\", name)) as f:\n",
    "#             print(len(f.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True     82995\nFalse     3529\nName: Image Index, dtype: int64"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "train_df['Image Index'].isin(filename_list).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['Image Index'].isin(filename_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True    82995\nName: Image Index, dtype: int64"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "train_df['Image Index'].isin(filename_list).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "False    82995\nName: Image Index, dtype: int64"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "train_df['Image Index'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[test_df['Image Index'].isin(filename_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       Finding Label       Image Index       h       w      x      y\n16183              3  00019124_073.png  2048.0  2500.0  0.168  0.168\n20445              9  00025787_054.png  2544.0  3056.0  0.139  0.139\n12788              1  00015666_002.png  2991.0  2992.0  0.143  0.143\n9316               8  00013111_111.png  2544.0  3056.0  0.139  0.139\n6013               6  00009845_046.png  2048.0  2500.0  0.168  0.168\n20926              1  00026478_007.png  2544.0  3056.0  0.139  0.139\n9047               4  00012834_073.png  2048.0  2500.0  0.168  0.168\n14500              5  00017236_073.png  2048.0  2500.0  0.168  0.168\n15817              8  00018721_009.png  2048.0  2500.0  0.168  0.168\n6098               9  00009889_015.png  2048.0  2500.0  0.168  0.168",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Finding Label</th>\n      <th>Image Index</th>\n      <th>h</th>\n      <th>w</th>\n      <th>x</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>16183</td>\n      <td>3</td>\n      <td>00019124_073.png</td>\n      <td>2048.0</td>\n      <td>2500.0</td>\n      <td>0.168</td>\n      <td>0.168</td>\n    </tr>\n    <tr>\n      <td>20445</td>\n      <td>9</td>\n      <td>00025787_054.png</td>\n      <td>2544.0</td>\n      <td>3056.0</td>\n      <td>0.139</td>\n      <td>0.139</td>\n    </tr>\n    <tr>\n      <td>12788</td>\n      <td>1</td>\n      <td>00015666_002.png</td>\n      <td>2991.0</td>\n      <td>2992.0</td>\n      <td>0.143</td>\n      <td>0.143</td>\n    </tr>\n    <tr>\n      <td>9316</td>\n      <td>8</td>\n      <td>00013111_111.png</td>\n      <td>2544.0</td>\n      <td>3056.0</td>\n      <td>0.139</td>\n      <td>0.139</td>\n    </tr>\n    <tr>\n      <td>6013</td>\n      <td>6</td>\n      <td>00009845_046.png</td>\n      <td>2048.0</td>\n      <td>2500.0</td>\n      <td>0.168</td>\n      <td>0.168</td>\n    </tr>\n    <tr>\n      <td>20926</td>\n      <td>1</td>\n      <td>00026478_007.png</td>\n      <td>2544.0</td>\n      <td>3056.0</td>\n      <td>0.139</td>\n      <td>0.139</td>\n    </tr>\n    <tr>\n      <td>9047</td>\n      <td>4</td>\n      <td>00012834_073.png</td>\n      <td>2048.0</td>\n      <td>2500.0</td>\n      <td>0.168</td>\n      <td>0.168</td>\n    </tr>\n    <tr>\n      <td>14500</td>\n      <td>5</td>\n      <td>00017236_073.png</td>\n      <td>2048.0</td>\n      <td>2500.0</td>\n      <td>0.168</td>\n      <td>0.168</td>\n    </tr>\n    <tr>\n      <td>15817</td>\n      <td>8</td>\n      <td>00018721_009.png</td>\n      <td>2048.0</td>\n      <td>2500.0</td>\n      <td>0.168</td>\n      <td>0.168</td>\n    </tr>\n    <tr>\n      <td>6098</td>\n      <td>9</td>\n      <td>00009889_015.png</td>\n      <td>2048.0</td>\n      <td>2500.0</td>\n      <td>0.168</td>\n      <td>0.168</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "test_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RescaleImage(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "            \n",
    "        The samples coming into this class will have its images reduced assuming\n",
    "        the input is a h, w, c numpy array\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        h, w = image.size\n",
    "\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = image.resize((new_h, new_w))\n",
    "\n",
    "        return {'image': img, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        image = np.array(image)\n",
    "        if len(image.shape) > 2:\n",
    "            image = image[:,:,0]\n",
    "\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        return {'image': torch.FloatTensor(image).unsqueeze(0),\n",
    "#         return {'image': torch.from_numpy(image),                \n",
    "                'label': torch.from_numpy(np.array(label))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  print([Image.open('../Datasets/Lungs_Dataset/Xray/'+train_df['Image Index'][each_import]).size for each_import in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note this will return an Image object, of h and w, and its corresponding label\n",
    "class CovidLungsDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, dataframe, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.dataframe['Image Index'][idx])\n",
    "        my_image = Image.open(img_name)        \n",
    "        if len(my_image.size) > 2:\n",
    "            assert len(my_image.size) > 2\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        label = row['Finding Label']\n",
    "        sample = {'image': my_image, 'label': label}\n",
    "        # sample.to(device)\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_train_set = CovidLungsDataset(train_df, my_path, transform=transforms.Compose([\n",
    "        RescaleImage(200),\n",
    "        ToTensor()\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(torch.Tensor, torch.Size([1, 200, 200]), tensor(8))"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "'''The original data coming out of the Dataset is a dictionary, \n",
    "the image is an Image object with the corresponding label.\n",
    "The size of all of these images are 1024 by 1024.\n",
    "The RescaleImage will convert the Image object to an Image object with 200x200 in size, \n",
    "leaving the label alone.\n",
    "The ToTensor will convert the Image object with 200x200 to tensors of 1x200x200'''\n",
    "from random import randint\n",
    "a_sample = my_train_set.__getitem__(randint(0,256))\n",
    "my_image = a_sample['image']\n",
    "my_label = a_sample['label']\n",
    "#imshow will work if it's h,w,c or h,w\n",
    "#torch is c,h,w\n",
    "#line below can be used if you don't use ToTensor\n",
    "# plt.imshow(my_image)\n",
    "type(my_image), my_image.shape, my_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor(99.5128)"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "my_image.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'sum'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-f1c8cd43b00d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_train_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meach\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'sum'"
     ]
    }
   ],
   "source": [
    "el = []\n",
    "for each in range(len(my_train_set)):\n",
    "    sample = my_train_set.__getitem__(each)\n",
    "    el.append(sample['image'].mean())\n",
    "print(el.sum()/len(el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(129.7539)\n"
    }
   ],
   "source": [
    "adder = 0\n",
    "for each in el:\n",
    "    adder += each\n",
    "pixel_mean = adder/len(el)\n",
    "print(pixel_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "el_var = []\n",
    "for each in range(len(my_train_set)):\n",
    "    sample = my_train_set.__getitem__(each)\n",
    "    a = sample['image']-pixel_mean\n",
    "    el_var.append((torch.mul(a, a)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(4183.0381)\n"
    }
   ],
   "source": [
    "adder2 = 0\n",
    "for each in el_var:\n",
    "    adder2 += each\n",
    "pixel_std = adder2/len(el_var)\n",
    "print(pixel_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor(64.6764)"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "torch.sqrt(pixel_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(my_image.squeeze(0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "batch_loader_params = {\n",
    "    \"batch_size\": 50,\n",
    "    \"shuffle\": True,\n",
    "    \"num_workers\": 0 if platform.system() == 'Windows' else 2\n",
    "}\n",
    "dataloader = DataLoader(my_train_set, **batch_loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter(dataloader).next()\n",
    "# for i, each in enumerate(dataloader):\n",
    "#     print(each['image'].shape, each['label'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_samples = iter(dataloader)\n",
    "# samples = batch_samples.next()\n",
    "# datset_batch = torchvision.utils.make_grid(samples['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,10))\n",
    "# for index, each in enumerate(datset_batch):\n",
    "#     plt.imshow(each.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_size(input_size: int, kernel_size: int, stride: int = 1, padding: int = 0):\n",
    "    # https://cs231n.github.io/convolutional-networks/\n",
    "    spatial_size = (input_size - kernel_size + 2 * padding)/stride + 1\n",
    "    assert spatial_size % 1 == 0\n",
    "    assert spatial_size > 0\n",
    "    return int(spatial_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "222\n"
    }
   ],
   "source": [
    "print(spatial_size(224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "print(spatial_size(75, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(spatial_size(13, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): Net(\n",
      "    (conv1): Conv2d(1, 200, kernel_size=(51, 51), stride=(1, 1))\n",
      "    (conv2): Conv2d(200, 75, kernel_size=(50, 50), stride=(1, 1))\n",
      "    (conv3): Conv2d(75, 13, kernel_size=(8, 8), stride=(1, 1))\n",
      "    (fc1): Linear(in_features=117, out_features=32, bias=True)\n",
      "    (fc2): Linear(in_features=32, out_features=15, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 200, 51, 1)\n",
    "        self.conv2 = nn.Conv2d(200, 75, 50, 1)        \n",
    "        self.conv3 = nn.Conv2d(75, 13, 8, 1)  \n",
    "        self.fc1 = nn.Linear(3*3*13, 32)\n",
    "        self.fc2 = nn.Linear(32, 15)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x)) # torch.Size([5, 1, 200, 200]) ==> torch.Size([5, 200, 150, 150])\n",
    "        x = F.max_pool2d(x, 2, 2) # torch.Size([5, 200, 150, 150]) ==> torch.Size([5, 200, 75, 75])\n",
    "        x = F.relu(self.conv2(x)) # torch.Size([5, 200, 75, 75]) ==> torch.Size([5, 75, 26, 26])\n",
    "        x = F.max_pool2d(x, 2, 2) # torch.Size([5, 75, 26, 26]) ==> torch.Size([5, 75, 13, 13])\n",
    "        x = F.relu(self.conv3(x)) # torch.Size([5, 75, 13, 13]) ==> torch.Size([5, 13, 6, 6])\n",
    "        x = F.max_pool2d(x, 2, 2) # torch.Size([5, 13, 6, 6]) ==> torch.Size([5, 13, 3, 3])\n",
    "        x = x.view(-1, 3*3*13)  # torch.Size([5, 13, 3, 3]) ==> torch.Size([5*32, 3*3*13])\n",
    "        x = F.relu(self.fc1(x))   # torch.Size([5*32, 3*3*13]) ==> torch.Size([5, 32])\n",
    "        x = self.fc2(x)           # torch.Size([5, 32]) ==> torch.Size([5, 15])\n",
    "        # # There's no activation at the final layer because of the criterion of CEL\n",
    "#         return x\n",
    "        return torch.log_softmax(x, dim=-1)\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net = nn.DataParallel(net)\n",
    "net.to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.NLLLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "#         inputs, labels = data['image'], data['label']\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(data['image'])\n",
    "#         print(outputs.shape, data['label'].shape)\n",
    "        loss = criterion(outputs, data['label'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        print('[%d, %5d] loss: %.5f' %\n",
    "              (epoch + 1, i + 1, running_loss / (epoch*i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}